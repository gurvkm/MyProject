{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOv/edx6jZa3rageNfEQ8Yj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gurvkm/MyProject/blob/master/project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UsltPtbz0YZc",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "**CREATING POST DISASTER ASSESMENT REPORT USING TWITTER DATA**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "#We are using hagupit typhoon data to fill all the enteries of a disaster report \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iHF3M_x30na",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "94c74d48-e5a7-4331-b030-675df9827dd8"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install --upgrade -q gspread\n",
        " \n",
        " \n",
        " \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        " \n",
        " \n",
        "from transformers import BertForQuestionAnswering\n",
        "from google.colab import drive\n",
        "from itertools import islice\n",
        "#auth.authenticate_user()\n",
        "#gc = gspread.authorize(GoogleCredentials.get_application_default())\n",
        "drive.mount('/content/drive/')\n",
        "#worksheet = gc.open('data_set.csv').sheet1\n",
        "#rows = worksheet.get_all_values()\n",
        "#pd.DataFrame.from_records(rows)\n",
        "model = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
        "from transformers import BertTokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
        "class_of_tweets=[\"victim\",\"resources\",\"damage\",\"responses\",\"intensity\"]\n",
        "for e in class_of_tweets:\n",
        "  if e==\"intensity\":\n",
        "    print(\"Intensity:\")\n",
        "    question_path=\"/content/drive/My Drive/Colab Notebooks/grouped question/intensity.txt\"\n",
        "    answer_path=\"/content/drive/My Drive/Colab Notebooks/grouped data/intensity.txt\"\n",
        "  if e==\"victim\":\n",
        "    print(\"Victim:\")\n",
        "    question_path=\"/content/drive/My Drive/Colab Notebooks/grouped question/victim.txt\"\n",
        "    answer_path=\"/content/drive/My Drive/Colab Notebooks/grouped data/victim.txt\"\n",
        "  if e==\"damage\":\n",
        "    print(\"Damage:\")\n",
        "    question_path=\"/content/drive/My Drive/Colab Notebooks/grouped question/damage.txt\"\n",
        "    answer_path=\"/content/drive/My Drive/Colab Notebooks/grouped data/damage.txt\"\n",
        "  if e==\"resources\":\n",
        "    print(\"Resources:\")\n",
        "    question_path=\"/content/drive/My Drive/Colab Notebooks/grouped question/resources.txt\"\n",
        "    answer_path=\"/content/drive/My Drive/Colab Notebooks/grouped data/resources.txt\"\n",
        "  if e==\"responses\":\n",
        "    print(\"Responses:\")\n",
        "    question_path=\"/content/drive/My Drive/Colab Notebooks/grouped question/responses.txt\"\n",
        "    answer_path=\"/content/drive/My Drive/Colab Notebooks/grouped data/responses.txt\"\n",
        " \n",
        "  question_file = open(question_path, \"r\")\n",
        "  question_set = question_file.readlines()\n",
        "  #Question_set=[]\n",
        "  #myquestion = question_file.readlines()\n",
        "  count=0\n",
        "  file1=open(\"/content/drive/My Drive/Colab Notebooks/answerfile3.txt\", \"a\")\n",
        "  file1.write(e)\n",
        "  file1.write(\"\\n\")\n",
        "  file1.write(\"\\n\")\n",
        "  file1.close()\n",
        "  for question in question_set:\n",
        "    file1=open(\"/content/drive/My Drive/Colab Notebooks/answerfile3.txt\", \"a\")\n",
        "    file1.write(\"\\n\")\n",
        "    file1.write\n",
        "    file1.write(\"Question{}: {}\".format(count,question.strip()))\n",
        "    file1.close()\n",
        "    print(question)\n",
        "    #print(\"Question{}: {}\".format(count, question.strip()))\n",
        "    chunks=1000\n",
        "    answer_file=open(answer_path,\"r\")\n",
        "    while True:\n",
        "      #answer_portion=islice(input_file,number_of_lines)\n",
        "      #print(answer_portion)\n",
        "      answer_text=answer_file.read(chunks)\n",
        "      if not answer_text:\n",
        "        break\n",
        "      \n",
        "      #print(answer_text)\n",
        "      #answer_text=answer_file.read()\n",
        "      #answer_file=open(answer_path,\"r\")\n",
        "      #answer_text=answer_file.read()\n",
        "      input_ids = tokenizer.encode(question, answer_text)\n",
        "      tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
        "      # For each token and its id...\n",
        "      for token, id in zip(tokens, input_ids):\n",
        "        #If this is the [SEP] token, add some space around it to make it stand out.\n",
        "        if id == tokenizer.sep_token_id:\n",
        "          print('')\n",
        "          # Print the token string and its ID in two columns\n",
        "          #print('{:<12} {:>6,}'.format(token, id))\n",
        "        #if id == tokenizer.sep_token_id:\n",
        "          #print('')\n",
        "          # Search the input_ids for the first instance of the `[SEP]` token.\n",
        "      sep_index = input_ids.index(tokenizer.sep_token_id)\n",
        "        # The number of segment A tokens includes the [SEP] token istelf.\n",
        "      num_seg_a = sep_index + 1\n",
        "       # The remainder are segment B.\n",
        "      num_seg_b = len(input_ids) - num_seg_a\n",
        "       # Construct the list of 0s and 1s.\n",
        "      segment_ids = [0]*num_seg_a + [1]*num_seg_b\n",
        "       # There should be a segment_id for every input token.\n",
        "      assert len(segment_ids) == len(input_ids)\n",
        "      start_scores, end_scores = model(torch.tensor([input_ids]), # The tokens representing our input text.\n",
        "                                token_type_ids=torch.tensor([segment_ids])) \n",
        "       #print(start_scores,end_scores)\n",
        "      answer_start = torch.argmax(start_scores)\n",
        "      answer_end = torch.argmax(end_scores)\n",
        "       #print(argmax(start_scores),argmax(end_scores))\n",
        "       # Combine the tokens in the answer and print it out.\n",
        "      answer = ' '.join(tokens[answer_start:answer_end+1])\n",
        "      \n",
        "      \n",
        "       #file1.write('Answer: \"' + answer + '\"')\n",
        "      answer = tokens[answer_start]\n",
        "       # Select the remaining answer tokens and join them with whitespace.\n",
        "      for i in range(answer_start + 1, answer_end + 1):\n",
        "        # If it's a subword token, then recombine it with the previous token.\n",
        "        if tokens[i][0:2] == '##':\n",
        "          answer += tokens[i][2:]\n",
        "          # Otherwise, add a space then the token\n",
        "        else:\n",
        "          answer += ' ' + tokens[i]\n",
        "      #print('Answer: \"' + answer + '\"')\n",
        "      file1=open(\"/content/drive/My Drive/Colab Notebooks/answerfile3.txt\", \"a\")\n",
        "      file1.write(\"\\n\")\n",
        "\n",
        "      file1.write(\"ANSWER:\"+answer+'')\n",
        "      file1.write(\"\\n\")\n",
        "      file1.close()\n",
        " \n",
        " \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (3.1.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: tokenizers==0.8.1.rc2 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8.1rc2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.91)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n",
            "Victim:\n",
            "How many child of age 5 years or less affected?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " How many Affected pregnant women are there?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "How many peoples are dead?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Number of peoples found to be dead?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Total casualties in the area are?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " How many peoples/persons are killed/kills?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Injuries are found to how many peoples?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "How many peoples lost there houses?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "How many people are homeless?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " How many people are on roads ?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Resources:\n",
            "Are there availability of community kitchen in the affected area?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "What are the sources of energy for cooking in the area?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "In case of emergency please contact to which numbers?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Which are emergency numbers provided by government/ngo/health officials?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Which Is the local hospital number?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "What are the helpline numbers?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "What are the helpline numbers?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Do the prices of the materials increasing/getting higher/lower/decreased ?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Are the materials getting costlier?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Where the child/student can learn from?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Are the any alternate arrangement for the students?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Anyone providing some Reading materials available with student?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Teaching materials availability/available with teachers or not?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "How is the motion level of the students/teachers now?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Are teachers/students feeling well or not?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "How many clothes are required for the children?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "How many kids/child requires clothes or dresses?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "How many clothes are required for the adults?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " How many young/peoples requires clothes or dresses?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "what are the Normal food consumption pattern of the affected population?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Indicate wether the food is available with the house hold?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Are foods avaible in the market to be served?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " Are any  food is available with the house hold?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "what are the Natures of the storage facilities?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Are Food available for all categories of population?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "How is the scaricity of the are?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "How is the Availability of medicine/drugs in the area?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "How many death after disaster has found?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "how is the Availability and Use of toilets in the area?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "How many Crops are  Damaged in the area?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Damage:\n",
            "What is the condition of the weather in the area?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "weather forecast says if there will be rain/sunny from ?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "If the After aftershocks/water level rising/falling/ flooding?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "The affected area comes under which districts.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Which is the most affected districts due to the event\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Which is the most affected blocks due to the event\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "which is the most affected area due to this disaster?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " which are the most affected cities due to this disaster?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "which is the most affected villages due to this disaster?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "the affected areas are mostly of type flat, low-lying coastal, mountain, other?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "area of these peoples are mostly depended on what as there source of income?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Peoples from these area are mostly depended on what as there livelihood?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "What are the socio-economic condition of this area?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "maximum damage found in which area?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " Worst affected area is in?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Which is the most suffering area due to the event?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Which area is hit the hardest?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "how is the network condition of these area?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " Roads of these areas are in the working condition or not?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "If Needs are in reachable condition or not?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "How many peoples are affected ?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "How many child of age 5 years or less affected?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " How many Affected pregnant women are there?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "How many peoples are dead?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Number of peoples found to be dead?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Total casualties in the area are?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " How many peoples/persons are killed/kills?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "How many peoples/persons are killed/kills?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Injuries are found to how many peoples?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " Number of peoples are missing?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "How many peoples lost there houses?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "How many people are homeless?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " How many people are on roads ?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "How many peoples flee or leave there houses \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "How many peoples are evacuated?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "How many peoples are lifted?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Are there availability of community kitchen in the affected area?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "What are the sources of energy for cooking in the area?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Which building is damage?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Which Railway station is damaged?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Which statue is damaged?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Which school/university/office is damaged?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "In case of emergency please contact to which numbers?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Which are emergency numbers provided by government/ngo/health officials?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Which Is the local hospital number?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "What are the helpline numbers?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Do the prices of the materials increasing/getting higher/lower/decreased ?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Are the materials getting costlier?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "How is the local government supporting to the peoples?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Are local government helping or not?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "How is the condition of schools/universities/colleges/institutes in the affected area?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Where the child/student can learn from?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Are the any alternate arrangement for the students?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Anyone providing some Reading materials available with student?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Teaching materials availability/available with teachers or not?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "How is the motion level of the students/teachers now?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Are teachers/students feeling well or not?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Chief minster/ local leader/ company said to help ?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Which state minister/prime minister/health minister/home minister/ minister said to help or providing or giving what?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Local NGO/CSO come forward to help or provide?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Which country prime minister/president/foreign minister promised to supply/help/give what ?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Which countries NGO/CSO company said to help or provide something ?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "How many clothes are required for the children?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "How many kids/child requires clothes or dresses?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "How many clothes are required for the adults?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " How many young/peoples requires clothes or dresses?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "what type of structures are damaged?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "What type of buildings are mostly affected?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "How many childres are going to losse there parents?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "what %/percentage of building/tower is damaged?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Are the damaged buildings can be repared?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "what are the Normal food consumption pattern of the affected population?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Indicate wether the food is available with the house hold?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Are foods avaible in the market to be served?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " Are any  food is available with the house hold?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "what are the Natures of the storage facilities?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Are Food available for all categories of population?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "How is the scaricity of the are?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "How is the Availability of medicine/drugs in the area?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "How many death after disaster has found?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "How many childrens have been died after disaster?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "What have been the main cause of death of this disaster?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Responses:\n",
            "How many peoples flee or leave there houses \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "How many peoples are evacuated?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "How many peoples are lifted?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Are there availability of community kitchen in the affected area?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "What are the sources of energy for cooking in the area?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "How is the local government supporting to the peoples?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Are local government helping or not?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Chief minster/ local leader/ company said to help ?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Which state minister/prime minister/health minister/home minister/ minister said to help or providing or giving what?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Local NGO/CSO come forward to help or provide?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Which country prime minister/president/foreign minister promised to supply/help/give what ?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Which countries NGO/CSO company said to help or provide something ?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Intensity:\n",
            "what is the time of occurrence? \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "When did the heavy rain started in the area?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "When did river water started entering the village/city/town/area.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "for how long the disaster took place?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "What was the magnitude of the earthquake?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "What was the radius of the cyclone?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "what is the speed of the typhoon?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "What was the height of the typhoon?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "What was the height of the wave?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "what was the level of the river above danger sign?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\'\\'question_path=\"/content/drive/My Drive/Colab Notebooks/question.csv.txt\"\\nanswer_path=\"/content/drive/My Drive/Colab Notebooks/answer.csv.txt\"\\n \\n \\nquestion_file = open(question_path, \"r\")\\nline = question_file.readline()\\nQuestion_set=[]\\nwhile True:\\n  my_question = question_file.readline()\\n  Question_set.append(my_question)\\n  if not my_question:\\n    break\\nfor e in Question_set:\\n  question=e\\n  \\n \\n \\n  \\n  #question_file.closed()\\n \\n  answer_file=open(answer_path,\"r\")\\n  answer_text=answer_file.read()\\n  \\n  input_ids = tokenizer.encode(question, answer_text)\\n  tokens = tokenizer.convert_ids_to_tokens(input_ids)\\n  # For each token and its id...\\n  for token, id in zip(tokens, input_ids):\\n    #If this is the [SEP] token, add some space around it to make it stand out.\\n    if id == tokenizer.sep_token_id:\\n        print(\\'\\')\\n    \\n    # Print the token string and its ID in two columns.\\n    #print(\\'{:<12} {:>6,}\\'.format(token, id))\\n \\n    if id == tokenizer.sep_token_id:\\n        print(\\'\\')\\n        # Search the input_ids for the first instance of the `[SEP]` token.\\n  sep_index = input_ids.index(tokenizer.sep_token_id)\\n    # The number of segment A tokens includes the [SEP] token istelf.\\n  num_seg_a = sep_index + 1\\n    # The remainder are segment B.\\n  num_seg_b = len(input_ids) - num_seg_a\\n    # Construct the list of 0s and 1s.\\n  segment_ids = [0]*num_seg_a + [1]*num_seg_b\\n    # There should be a segment_id for every input token.\\n  assert len(segment_ids) == len(input_ids)\\n  start_scores, end_scores = model(torch.tensor([input_ids]), # The tokens representing our input text.\\n                                token_type_ids=torch.tensor([segment_ids])) \\n  \\n  #print(start_scores,end_scores)\\n  answer_start = torch.argmax(start_scores)\\n  answer_end = torch.argmax(end_scores)\\n  #print(argmax(start_scores),argmax(end_scores))\\n    # Combine the tokens in the answer and print it out.\\n  answer = \\' \\'.join(tokens[answer_start:answer_end+1])\\n  print(\\'Answer: \"\\' + answer + \\'\"\\')\\n  answer = tokens[answer_start]\\n    # Select the remaining answer tokens and join them with whitespace.\\n  for i in range(answer_start + 1, answer_end + 1):\\n      # If it\\'s a subword token, then recombine it with the previous token.\\n    if tokens[i][0:2] == \\'##\\':\\n      answer += tokens[i][2:]\\n        # Otherwise, add a space then the token\\n    else:\\n      answer += \\' \\' + tokens[i]\\n  print(\\'Answer: \"\\' + answer + \\'\"\\')'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvcO3d7U0ZBg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyPLTX4A0aCY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ww1xuyBlpZLQ",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfMxzTNmpclL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxrlxKH6pdHP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_iqopdl4ogy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}